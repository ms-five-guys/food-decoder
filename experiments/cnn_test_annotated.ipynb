{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### êµ¬ë™í™˜ê²½\n",
    "azure notebook,  python3.8-pytorch and Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739929652000
    }
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install torch torchvision torchaudio matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739941968976
    }
   },
   "outputs": [],
   "source": [
    "# PyTorch ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image                           # ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ëª…\n",
    "1. **torch** (PyTorch í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬)\n",
    "    \n",
    "    PyTorchì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    í…ì„œ ì—°ì‚°(Tensor Operations), ìë™ ë¯¸ë¶„(Autograd) ê¸°ëŠ¥ í¬í•¨\n",
    "\n",
    "\n",
    "2. **torchvision** (PyTorch ì»´í“¨í„° ë¹„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬)\n",
    "    \n",
    "    ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë° ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    \n",
    "    ì£¼ìš” ê¸°ëŠ¥:\n",
    "    torchvision.datasets â†’ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "    torchvision.transforms â†’ ì´ë¯¸ì§€ ë³€í™˜ (í¬ê¸° ì¡°ì •, ì •ê·œí™” ë“±)\n",
    "    torchvision.models â†’ ì‚¬ì „ í›ˆë ¨ëœ CNN ëª¨ë¸ (ResNet, VGG ë“±)\n",
    "\n",
    "\n",
    "3. **torchvision.transforms** (ì´ë¯¸ì§€ ë³€í™˜ ë° ì „ì²˜ë¦¬)\n",
    "    \n",
    "    ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬(Preprocessing) í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ\n",
    "    í¬ê¸° ì¡°ì •, ì •ê·œí™”, Tensor ë³€í™˜ ë“± ìˆ˜í–‰ ê°€ëŠ¥\n",
    "\n",
    "\n",
    "4. **torch.nn** (ì‹ ê²½ë§ ë ˆì´ì–´ ë° ì†ì‹¤ í•¨ìˆ˜)\n",
    "    \n",
    "    ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´ ë° ì†ì‹¤ í•¨ìˆ˜ ì œê³µ\n",
    "\n",
    "\n",
    "5. **torch.optim** (ìµœì í™” ì•Œê³ ë¦¬ì¦˜)\n",
    "    \n",
    "    SGD, Adam ë“± ë‹¤ì–‘í•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ í¬í•¨\n",
    "\n",
    "6. **torch.utils.data.DataLoader** (ë°ì´í„° ë¡œë”)\n",
    "    \n",
    "    ë°ì´í„°ì…‹ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•˜ë„ë¡ í•˜ëŠ” ë„êµ¬\n",
    "    \n",
    "    **shuffle=True** â†’ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ í•™ìŠµ\n",
    "    \n",
    "    **batch_size=n** â†’ í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„° ê°œìˆ˜ ì„¤ì •\n",
    "\n",
    "\n",
    "7. **torchvision.datasets.ImageFolder** (ì´ë¯¸ì§€ í´ë”ì—ì„œ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°)\n",
    "   \n",
    "    í´ë” êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    ê° í´ë” ì´ë¦„ì„ **í´ë˜ìŠ¤ ë¼ë²¨(Label)**ë¡œ ìë™ ì¸ì‹\n",
    "\n",
    "\n",
    "8. **matplotlib.pyplot** (ë°ì´í„° ì‹œê°í™”)\n",
    "    \n",
    "    ê·¸ë˜í”„, ì´ë¯¸ì§€ ë“±ì„ ì‹œê°í™”í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "\n",
    "9. **os** (íŒŒì¼ ë° í´ë” ì¡°ì‘)\n",
    "    \n",
    "    ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ ì œê³µ\n",
    "    í´ë” ë‚´ íŒŒì¼ í™•ì¸, í´ë” ìƒì„± ë“± ê°€ëŠ¥\n",
    "\n",
    "10. **PIL (Python Imaging Library)**ëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‘ì—… ì „ ê²½ë¡œ í™•ì¸\n",
    "í•´ë‹¹ ê³¼ì •ì€ ê²½ë¡œë¥¼ ì •í™•íˆ ì„¤ì • ì‹œ ìƒëµ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944256661
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set\n",
      "Train í´ë” ì¡´ì¬ ì—¬ë¶€: False\n",
      "Test í´ë” ì¡´ì¬ ì—¬ë¶€: False\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ ì‘ì—… í´ë” í™•ì¸ ë° ë°ì´í„° í´ë” ì¡´ì¬ ì—¬ë¶€ ì²´í¬\n",
    "\n",
    "\n",
    "print(\"í˜„ì¬ ì‘ì—… í´ë”:\", os.getcwd())  # í˜„ì¬ ì‘ì—… ì¤‘ì¸ í´ë” í™•ì¸\n",
    "print(\"Train í´ë” ì¡´ì¬ ì—¬ë¶€:\", os.path.exists(\"./data_set/sample_data/train\")) #í•´ë‹¹í´ë”ì— train ë°ì´í„° ì…‹ì´ ì¡´ì¬ í•˜ë©´True\n",
    "print(\"Test í´ë” ì¡´ì¬ ì—¬ë¶€:\", os.path.exists(\"./data_set/sample_data/test\")) #í•´ë‹¹í´ë”ì— test ë°ì´í„° ì…‹ì´ ì¡´ì¬ í•˜ë©´True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944315436
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ” í´ë”: /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set\n",
      "âœ… ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ” í´ë”: /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test\n",
      "âœ… ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ” í´ë”: /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml\n",
      "âŒ ë°ì´í„°ì…‹ ì—†ìŒ: /home/user/data_set\n"
     ]
    }
   ],
   "source": [
    "# CNN ë°ì´í„°ì…‹ì´ ì–´ë””ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "base_paths = [\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set\",\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test\",\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml\",\n",
    "    \"/home/user/data_set\"  # ì˜ˆìƒë˜ëŠ” ë‹¤ë¥¸ ê²½ë¡œì— ë°ì´í„°ê°€ ìˆëŠ” ì§€ í‘œì‹œ\n",
    "]\n",
    "\n",
    "\n",
    "#base_pathsì˜ ì£¼ì†Œ(í´ë”)ì— ìˆìœ¼ë©´ âœ… ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ” í´ë”: ì£¼ì†Œ(í´ë” ìœ„ì¹˜)í‘œì‹œ\n",
    "#base_pathsì˜ ì£¼ì†Œ(í´ë”)ì— ì—†ìœ¼ë©´ âŒ ë°ì´í„°ì…‹ ì—†ìŒ: ì£¼ì†Œ(í´ë” ìœ„ì¹˜)í‘œì‹œ\n",
    "for path in base_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ëŠ” í´ë”: {path}\")\n",
    "    else:\n",
    "        print(f\"âŒ ë°ì´í„°ì…‹ ì—†ìŒ: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# ì‘ì—… ê²½ë¡œ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944366365
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train í´ë” ì¡´ì¬ ì—¬ë¶€: True\n",
      "Test í´ë” ì¡´ì¬ ì—¬ë¶€: True\n",
      "âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "train_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set/sample_data/train\"\n",
    "test_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set/sample_data/test\"\n",
    "\n",
    "# 1ï¸âƒ£ í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "print(f\"Train í´ë” ì¡´ì¬ ì—¬ë¶€: {os.path.exists(train_path)}\")  # í•™ìŠµ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "print(f\"Test í´ë” ì¡´ì¬ ì—¬ë¶€: {os.path.exists(test_path)}\")  # í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "\n",
    "# 2ï¸âƒ£ ì´ë¯¸ì§€ ë³€í™˜(ì „ì²˜ë¦¬) ì„¤ì •\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 128x128 í¬ê¸°ë¡œ ë³€í™˜ (ëª¨ë¸ ì…ë ¥ í¬ê¸° í†µì¼)\n",
    "    transforms.ToTensor(),  # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PyTorch í…ì„œ(Tensor) í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # RGB ê°’ ì •ê·œí™” (-1 ~ 1 ë²”ìœ„)\n",
    "])\n",
    "\n",
    "# 3ï¸âƒ£ ë°ì´í„° ë¡œë“œ (ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€)\n",
    "try:\n",
    "    train_dataset = datasets.ImageFolder(root=train_path, transform=transform)  # í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    test_dataset = datasets.ImageFolder(root=test_path, transform=transform)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    print(\"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ!\")  # ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ ì‹œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}\")  # ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì´ë¯¸ì§€ë³€í™˜(ì „ì²˜ë¦¬)\n",
    "**transforms.Resize((128, 128))**\n",
    " â†’  ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í¬ê¸° 128x128 í”½ì…€ë¡œ ë³€í™˜ (CNN ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¥¼ í†µì¼í•˜ê¸° ìœ„í•´ í•„ìš”)\n",
    "\n",
    "**transforms.ToTensor()**\n",
    " â†’  ì´ë¯¸ì§€ë¥¼ í…ì„œ(Tensor) í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (PyTorchì—ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•¨)\n",
    "\n",
    "**transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])**\n",
    " â†’  ê° í”½ì…€ ê°’ì„ -1 ~ 1 ë²”ìœ„ë¡œ ì •ê·œí™”(Normalization)\n",
    "(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]ì€ RGB ê° ì±„ë„ì— ì ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë°ì´í„°ì…‹ ë¡œë“œ & ì˜ˆì™¸ ì²˜ë¦¬\n",
    "**datasets.ImageFolder(root=train_path, transform=transform)**\n",
    " â†’  train_path í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ìœ„ì—ì„œ ì •ì˜í•œ transformì„ ì ìš©\n",
    "\n",
    "**ì˜ˆì™¸ ì²˜ë¦¬ (try-except ë¬¸)**\n",
    " â†’  ë§Œì•½ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ FileNotFoundErrorê°€ ë°œìƒí•˜ì—¬ \"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\" ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchì˜ DataLoader ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë‹ˆë°°ì¹˜(mini-batch) í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944387633
    }
   },
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ DataLoader ì„¤ì • (ë°°ì¹˜ í¬ê¸°: 32)\n",
    "# ë°°ì¹˜ ì‚¬ì´ì¦ˆì˜ ê²½ìš° ì„ì˜ë¡œ ì¡°ì •ê°€ëŠ¥\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # í•™ìŠµ ë°ì´í„° ë¡œë” (ëœë¤ ì…”í”Œ)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” (ìˆœì°¨ì  ë¡œë“œ)\n",
    "\n",
    "# 2ï¸âƒ£ ë°ì´í„° í™•ì¸ (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì¶œë ¥)\n",
    "for images, labels in train_loader:\n",
    "    print(f\"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ë¯¸ì§€ í¬ê¸°: {images.shape}, ë ˆì´ë¸” í¬ê¸°: {labels.shape}\")\n",
    "    break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸í•˜ê³  ë£¨í”„ ì¢…ë£Œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_datasetê³¼ test_datasetì„ ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ë¡œë”©\n",
    "batch_size=32 â†’ í•œ ë²ˆì— 32ê°œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\n",
    "\n",
    "\n",
    "**shuffle=True**\n",
    "train_loaderì˜ ê²½ìš° ë°ì´í„°ë¥¼ ëœë¤ìœ¼ë¡œ ì„ì–´ì„œ ë¶ˆëŸ¬ì˜´ (í•™ìŠµì— ì¤‘ìš”í•œ ì—­í• )\n",
    "test_loaderëŠ” shuffle=Falseë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„° ìˆœì„œë¥¼ ìœ ì§€ (í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¼ê´€ì„± í™•ë³´)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#  PyTorch ê¸°ë°˜ CNN(í•©ì„±ê³± ì‹ ê²½ë§, Convolutional Neural Network) ëª¨ë¸ì„ ì •ì˜ ë° ìŒì‹ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944450962
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 19ê°œì˜ ìŒì‹ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ CNN(Convolutional Neural Network) ëª¨ë¸ ì •ì˜\n",
    "class FoodCNN(nn.Module):  # nn.Moduleì„ ìƒì†ë°›ì•„ ìƒˆë¡œìš´ ì‹ ê²½ë§ ì •ì˜\n",
    "    def __init__(self, num_classes):\n",
    "        super(FoodCNN, self).__init__()  # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "\n",
    "        # 1ï¸âƒ£ í•©ì„±ê³±(Convolutional) layer ì •ì˜\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)  # ì…ë ¥(3ì±„ë„) â†’ 32ì±„ë„ feature map\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)  # 32ì±„ë„ â†’ 64ì±„ë„ feature map\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)  # 64ì±„ë„ â†’ 128ì±„ë„ featur map\n",
    "\n",
    "        # 2ï¸âƒ£ í’€ë§(Pooling) layer ì •ì˜\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 í¬ê¸°ì˜ ë§¥ìŠ¤í’€ë§ ì ìš© (íŠ¹ì§• ë§µ í¬ê¸° ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ)\n",
    "\n",
    "        # 3ï¸âƒ£ ì™„ì „ ì—°ê²°(Fully Connected) ë ˆì´ì–´ ì •ì˜\n",
    "        self.fc1 = nn.Linear(in_features=128 * 16 * 16, out_features=512)  # 128ì±„ë„ * 16 * 16 í¬ê¸°ì˜ ë²¡í„° â†’ 512 ë‰´ëŸ°\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=num_classes)  # 512 ë‰´ëŸ° â†’ ìŒì‹ í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ğŸ“Œ ìˆœì „íŒŒ(Forward) ê³¼ì • ì •ì˜\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 â†’ ReLU â†’ MaxPooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 â†’ ReLU â†’ MaxPooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Conv3 â†’ ReLU â†’ MaxPooling\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # ğŸ“Œ í…ì„œë¥¼ í¼ì³ì„œ(Flatten) ì™„ì „ ì—°ê²°ì¸µì— ì „ë‹¬\n",
    "        x = F.relu(self.fc1(x))  # ì™„ì „ ì—°ê²° ë ˆì´ì–´ 1 + ReLU\n",
    "        x = self.fc2(x)  # ì™„ì „ ì—°ê²° ë ˆì´ì–´ 2 (ì¶œë ¥ì¸µ)\n",
    "\n",
    "        return x  # ìµœì¢… ì¶œë ¥ê°’ ë°˜í™˜\n",
    "\n",
    "# ğŸ“Œ í´ë˜ìŠ¤ ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "num_classes = len(train_dataset.classes)  # `train_dataset`ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ ê°€ì ¸ì˜´\n",
    "print(f\"âœ… ì´ {num_classes}ê°œì˜ ìŒì‹ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ğŸ“Œ ëª¨ë¸ ìƒì„±\n",
    "model = FoodCNN(num_classes)  # FoodCNN ëª¨ë¸ì„ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Œ ì •ë¦¬\n",
    "\n",
    "**CNNì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ**\n",
    "\n",
    "CNNì€ ì£¼ë¡œ **í•©ì„±ê³± ë ˆì´ì–´(Convolutional Layer), í™œì„±í™” í•¨ìˆ˜(ReLU), í’€ë§ ë ˆì´ì–´(Pooling Layer), ì™„ì „ ì—°ê²° ë ˆì´ì–´(Fully Connected Layer)** ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "1. **í•©ì„±ê³±(Convolution) ë ˆì´ì–´**:\n",
    "    ì´ë¯¸ì§€ë¥¼ ì‘ì€ í•„í„°(Filter, Kernel) ë¡œ ìŠ¤ìº”í•˜ì—¬ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê³¼ì •\n",
    "\n",
    "    ì£¼ìš” íŠ¹ì§•:ì‘ì€ í•„í„°(ì˜ˆ: 3Ã—3, 5Ã—5)ë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ ë¶„ì„\n",
    "    ì—£ì§€(edge), ëª¨ì„œë¦¬, í…ìŠ¤ì²˜(texture) ë“±ì˜ íŒ¨í„´ì„ ê°ì§€\n",
    "    stride(ì´ë™ í¬ê¸°)ì™€ padding(ê²½ê³„ ì²˜ë¦¬)ì„ ì„¤ì •í•˜ì—¬ ì¶œë ¥ í¬ê¸° ì¡°ì ˆ\n",
    "\n",
    "2. **í™œì„±í™” í•¨ìˆ˜ (ReLU)**:\n",
    "    ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€í•˜ì—¬ ì‹ ê²½ë§ì´ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í•¨ìˆ˜\n",
    "    ReLU(Rectified Linear Unit) ê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©\n",
    "\n",
    "    ìŒìˆ˜ ê°’ì€ 0ìœ¼ë¡œ ë³€í™˜í•˜ê³ , **ì–‘ìˆ˜ ê°’ì€ ê·¸ëŒ€ë¡œ ìœ ì§€**\n",
    "    ì„ í˜•(Linear) ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ë©´ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ì—†ìŒ -> ReLUë¥¼ ì ìš©í•˜ë©´ ì‹ ê²½ë§ì´ ë” ê¹Šì–´ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ì„±ëŠ¥ì´ í–¥ìƒë¨\n",
    "\n",
    "3. **í’€ë§(Pooling) ë ˆì´ì–´**:\n",
    "    íŠ¹ì§• ë§µì˜ í¬ê¸°ë¥¼ ì¤„ì´ê³  ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¸°ëŠ” ê³¼ì •\n",
    "\n",
    "    ì£¼ìš” ê¸°ëŠ¥:ì—°ì‚°ëŸ‰ ê°ì†Œ â†’ ëª¨ë¸ì´ ë” ê°€ë²¼ì›Œì§\n",
    "    ê³¼ì í•©(Overfitting) ë°©ì§€ â†’ íŠ¹ì • íŠ¹ì§•ì´ ë„ˆë¬´ ê°•ì¡°ë˜ëŠ” ê²ƒì„ ë°©ì§€\n",
    "    ìœ„ì¹˜ ë³€í™”ì— ëŒ€í•œ ë¶ˆë³€ì„±(Translation Invariance) ìœ ì§€\n",
    "\n",
    "4. **ì™„ì „ ì—°ê²°(Fully Connected, FC) ë ˆì´ì–´**:\n",
    "    CNNì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ, í•©ì„±ê³± ë ˆì´ì–´ì—ì„œ ì¶”ì¶œëœ ê³ ìœ í•œ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—­í• \n",
    "    ì¼ë°˜ì ì¸ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP) êµ¬ì¡°ì™€ ë™ì¼\n",
    "\n",
    "    Flatten ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ 2D â†’ 1D ë²¡í„° ë³€í™˜ í›„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜(loss function) ë° ì˜µí‹°ë§ˆì´ì €(optimizer) ë¥¼ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739944463736
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ“Œ GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™ (ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ CPU ì‚¬ìš©)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # ëª¨ë¸ì„ í•´ë‹¹ ì¥ì¹˜(GPU ë˜ëŠ” CPU)ë¡œ ì´ë™\n",
    "\n",
    "# ğŸ“Œ ì†ì‹¤ í•¨ìˆ˜ ì •ì˜ (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì´ë¯€ë¡œ CrossEntropyLoss ì‚¬ìš©)\n",
    "criterion = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "# ğŸ“Œ ì˜µí‹°ë§ˆì´ì € ì •ì˜ (Adam ì‚¬ìš©, í•™ìŠµë¥ : 0.001) \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì†ì‹¤ í•¨ìˆ˜(Loss Function) ì •ì˜**\n",
    "    nn.CrossEntropyLoss()\n",
    "    â†’ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜(Multi-class Classification) ì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "    ì‚¬ìš© ì´ìœ :\n",
    "    í´ë˜ìŠ¤ ê°„ í™•ë¥  ë¶„í¬ë¥¼ ë¹„êµí•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê°€,\n",
    "    Softmaxì™€ Negative Log Likelihood(NLL)ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ í¬í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì˜µí‹°ë§ˆì´ì €(Optimizer)**:\n",
    "\n",
    "    ì˜µí‹°ë§ˆì´ì €(Optimizer) ëŠ” ì‹ ê²½ë§ì´ í•™ìŠµí•  ë•Œ **ê°€ì¤‘ì¹˜(weight)ì™€ í¸í–¥(bias)**ì„ ì¡°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.\n",
    "    ì¦‰, ì˜µí‹°ë§ˆì´ì €ëŠ” **ì†ì‹¤ í•¨ìˆ˜(Loss Function) ë¥¼ ìµœì†Œí™”**í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì—­í• ì„ í•œë‹¤.\n",
    "\n",
    "    ì—­í• :\n",
    "    ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°(Gradient)ë¥¼ ê³„ì‚°\n",
    "    backpropagation(ì—­ì „íŒŒ)ì„ í†µí•´ ì†ì‹¤ í•¨ìˆ˜ì˜ ë³€í™”ëŸ‰ì„ êµ¬í•¨\n",
    "\n",
    "    ê¸°ìš¸ê¸° ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •\n",
    "    ì†ì‹¤ì´ ê°ì†Œí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\n",
    "\n",
    "    í•™ìŠµë¥ (learning rate)ì— ë”°ë¼ ì—…ë°ì´íŠ¸ í¬ê¸°ë¥¼ ì¡°ì ˆ\n",
    "    ë„ˆë¬´ í¬ë©´ ìµœì ê°’ì„ ì§€ë‚˜ì¹  ìˆ˜ ìˆê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ ìˆ˜ë ´ ì†ë„ê°€ ëŠë¦¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# ì´ë¯¸ì§€ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1739945127676
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1135\n",
      "Epoch [2/20], Loss: 0.3461\n",
      "Epoch [3/20], Loss: 0.1933\n",
      "Epoch [4/20], Loss: 0.0712\n",
      "Epoch [5/20], Loss: 0.0301\n",
      "Epoch [6/20], Loss: 0.0099\n",
      "Epoch [7/20], Loss: 0.0083\n",
      "Epoch [8/20], Loss: 0.0012\n",
      "Epoch [9/20], Loss: 0.0013\n",
      "Epoch [10/20], Loss: 0.0006\n",
      "Epoch [11/20], Loss: 0.0004\n",
      "Epoch [12/20], Loss: 0.0003\n",
      "Epoch [13/20], Loss: 0.0003\n",
      "Epoch [14/20], Loss: 0.0002\n",
      "Epoch [15/20], Loss: 0.0002\n",
      "Epoch [16/20], Loss: 0.0002\n",
      "Epoch [17/20], Loss: 0.0002\n",
      "Epoch [18/20], Loss: 0.0002\n",
      "Epoch [19/20], Loss: 0.0002\n",
      "Epoch [20/20], Loss: 0.0001\n",
      "âœ… í•™ìŠµ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # í•™ìŠµí•  ì—í¬í¬ ìˆ˜\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # GPUë¡œ ì´ë™\n",
    "\n",
    "        optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        outputs = model(images)  # ëª¨ë¸ ì˜ˆì¸¡\n",
    "        loss = criterion(outputs, labels)  # ì†ì‹¤ ê³„ì‚°\n",
    "        loss.backward()  # ì—­ì „íŒŒ\n",
    "        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **model.train() : ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •**\n",
    "\n",
    "    PyTorch ëª¨ë¸ì—ëŠ” í•™ìŠµ ëª¨ë“œ(train())ì™€ í‰ê°€ ëª¨ë“œ(eval()) ê°€ ìˆìŒ\n",
    "\n",
    "    model.train()ì„ í˜¸ì¶œí•˜ë©´:**Dropout, Batch Normalization** ë“± í•™ìŠµ ê´€ë ¨ ê¸°ëŠ¥ í™œì„±í™” -> ëª¨ë¸ì´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ í•™ìŠµ ëª¨ë“œë¡œ ìˆ˜í–‰\n",
    "\n",
    "\n",
    "    ì™œ í•„ìš”í•œê°€?\n",
    "\n",
    "    ëª¨ë“œì— ë”°ë¼ ë™ì‘ì´ ë‹¬ë¼ì§\n",
    "    train() ëª¨ë“œì—ì„œëŠ” **Dropout**ì´ í™œì„±í™”ë˜ê³ , eval() ëª¨ë“œì—ì„œëŠ” ë¹„í™œì„±í™”ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **optimizer.zero_grad():** ì´ì „ ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "\n",
    "    ì´ì „ ë°°ì¹˜ì—ì„œ ê³„ì‚°ëœ ê¸°ìš¸ê¸°(Gradient)ë¥¼ ì œê±°\n",
    "\n",
    "    PyTorchëŠ” **ê¸°ìš¸ê¸°ë¥¼ ëˆ„ì (accumulate)í•˜ëŠ” ë°©ì‹**ì´ë¯€ë¡œ, \n",
    "    zero_grad()ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ì´ì „ ë°°ì¹˜ì˜ ê¸°ìš¸ê¸°ê°€ ë‚¨ì•„ ìˆìŒ â†’ í•™ìŠµì´ ì˜ëª»ë  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **outputs = model(images): ìˆœì „íŒŒ(Forward Propagation)**\n",
    "\n",
    "    images(ì…ë ¥ ë°ì´í„°)ë¥¼ CNN ëª¨ë¸ì— í†µê³¼ì‹œì¼œ ì˜ˆì¸¡ê°’ì„ ìƒì„±\n",
    "\n",
    "    CNN ëª¨ë¸ ë‚´ë¶€ì—ì„œ: í•©ì„±ê³±(Convolution) â†’ í™œì„±í™” í•¨ìˆ˜(ReLU) â†’ í’€ë§(Pooling) â†’ ì™„ì „ ì—°ê²°(FC) ë ˆì´ì–´ë¥¼ ê±°ì³ ì¶œë ¥ê°’ì„ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **loss = criterion(outputs, labels): ì†ì‹¤ ê³„ì‚°**\n",
    "    \n",
    "    ì†ì‹¤ í•¨ìˆ˜(criterion)ë¥¼ ì‚¬ìš©í•´ ì˜ˆì¸¡ê°’(outputs)ê³¼ ì‹¤ì œê°’(labels)ì˜ ì°¨ì´ë¥¼ ê³„ì‚°\n",
    "    \n",
    "    CrossEntropyLoss()ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ í™•ë¥  ë¶„í¬ ê¸°ë°˜ ì†ì‹¤ ê³„ì‚°\n",
    "    \n",
    "    loss.item()ì„ ì´ìš©í•˜ë©´ ì†ì‹¤ ê°’(ìŠ¤ì¹¼ë¼ ê°’)ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **loss.backward(): ì—­ì „íŒŒ(Backpropagation)**\n",
    "\n",
    "    ì†ì‹¤ í•¨ìˆ˜ì— ëŒ€í•œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ê¸°ìš¸ê¸°(Gradient) ê³„ì‚°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **optimizer.step(): ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸**\n",
    "ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜(weight)ì™€ í¸í–¥(bias)ë¥¼ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **print(f\"Epoch [{epoch+1}/{num_epochs}]**,  **Loss: {running_loss/len(train_loader):.4f}\"): í•™ìŠµ ì§„í–‰ í™•ì¸**\n",
    "running_lossëŠ” í•œ epoch ë™ì•ˆì˜ ì „ì²´ ì†ì‹¤ì„ ì €ì¥ -> í‰ê·  ì†ì‹¤ì„ ì¶œë ¥í•˜ì—¬ ëª¨ë¸ì´ í•™ìŠµí•˜ë©´ì„œ ì†ì‹¤ì´ ì ì  ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1739945131188
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: 28.42%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # í‰ê°€ ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚° X\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# âœ… ì¶”ê°€ ê¸°ëŠ¥: ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡\n",
    "ì‚¬ìš©ìê°€ ì§ì ‘ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "â†’ PIL.Image.open()ìœ¼ë¡œ ë¡œë“œ\n",
    "ëª¨ë¸ì´ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜ ì ìš©\n",
    "â†’ transformsë¥¼ ì‚¬ìš©í•´ Tensor ë³€í™˜\n",
    "ëª¨ë¸ì„ í™œìš©í•´ ë¶„ë¥˜\n",
    "â†’ model(image_tensor.unsqueeze(0)) í˜•íƒœë¡œ ì˜ˆì¸¡\n",
    "ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n",
    "â†’ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¡œ ìŒì‹ ë¶„ë¥˜\n",
    "\n",
    "# \n",
    "ğŸ“Œ ì½”ë“œ: ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì˜ˆì¸¡ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739945825024
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-6a025-ml/code/Users/6a025/cnn_test/data_set\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ ì‘ì—… í´ë” í™•ì¸ ë° ë°ì´í„° í´ë” ì¡´ì¬ ì—¬ë¶€ ì²´í¬\n",
    "\n",
    "print(\"í˜„ì¬ ì‘ì—… í´ë”:\", os.getcwd())  # í˜„ì¬ ìœ„ì¹˜ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739945859997
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ í´ë” ë‚´ íŒŒì¼ ëª©ë¡: ['.amlignore', '.amlignore.amltmp', 'Img_119_0214.jpg', 'Img_119_0215.jpg', 'Img_119_0275.jpg', 'Img_119_0288.jpg', 'Img_119_0296.jpg', 'sample_image.jpg']\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ í´ë” ë‚´ ì´ë¯¸ì§€ í™•ì¸\n",
    "test_folder = \"./sample_data/test/ê¹€ì¹˜ì°Œê°œ\"\n",
    "print(\"ğŸ“‚ í´ë” ë‚´ íŒŒì¼ ëª©ë¡:\", os.listdir(test_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1739945954884
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ì˜ˆì¸¡ ê²°ê³¼: ê¹€ì¹˜ì°Œê°œ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì˜ˆì¸¡í•  ì´ë¯¸ì§€ ì§€ì •)\n",
    "image_path = \"./sample_data/test/ê¹€ì¹˜ì°Œê°œ/sample_image.jpg\"  # ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥\n",
    "\n",
    "# ğŸ“Œ ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "image = Image.open(image_path)  # ì´ë¯¸ì§€ íŒŒì¼ ì—´ê¸°\n",
    "\n",
    "# ğŸ“Œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶”ê¸°)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë³€í™˜\n",
    "    transforms.ToTensor(),  # PyTorch í…ì„œ(Tensor)ë¡œ ë³€í™˜\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ì •ê·œí™” (-1~1 ë²”ìœ„)\n",
    "])\n",
    "image = transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (ëª¨ë¸ ì…ë ¥ì„ ìœ„í•´ í•„ìš”)\n",
    "\n",
    "# ğŸ“Œ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "model.eval()\n",
    "\n",
    "# ğŸ“Œ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "with torch.no_grad():  # í‰ê°€ ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚° X\n",
    "    output = model(image)  # ëª¨ë¸ì— ì´ë¯¸ì§€ ì…ë ¥\n",
    "    predicted_class = torch.argmax(output, 1).item()  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ\n",
    "\n",
    "# ğŸ“Œ í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (í•™ìŠµ ë°ì´í„° í´ë”ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ)\n",
    "class_names = os.listdir(\"./sample_data/train\")  # í•™ìŠµ ë°ì´í„° íŒŒì¼ì˜ í´ë”ëª… ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "# ğŸ“Œ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ“Œ ì˜ˆì¸¡ ê²°ê³¼: {class_names[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ ì‹¤í–‰ íë¦„ ì •ë¦¬\n",
    "\n",
    "1ï¸âƒ£ ì´ë¯¸ì§€ ë¡œë“œ (PIL.Image.open())\n",
    "\n",
    "2ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Resize â†’ ToTensor â†’ Normalize â†’ unsqueeze(0))\n",
    "\n",
    "3ï¸âƒ£ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (model.eval())\n",
    "\n",
    "4ï¸âƒ£ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ (torch.argmax(output, 1))\n",
    "\n",
    "5ï¸âƒ£ í•™ìŠµ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸° (os.listdir())\n",
    "\n",
    "6ï¸âƒ£ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ (print(class_names[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
